{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7a27ff-fee4-4513-a60d-2d6118a08877",
   "metadata": {},
   "source": [
    "# Plymouth High School Graduation Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45179e2-bfcf-45b4-ae07-fae11cdca772",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This project analyzes student data, including course history, attendance records, and state testing scores, to predict high school graduation outcomes using machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0c446-e319-41a4-bc78-f6253fdd4f7b",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4af54-35d2-4652-b582-98d1974d95dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524c4dc-1dc8-4790-bd3b-6a804504599c",
   "metadata": {},
   "source": [
    "## 3. Loading, Exploring, & Cleaning Course History Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721625f-f8ca-4029-993e-b97d9d74ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Course History Excel file\n",
    "df = pd.read_excel('Plymouth Data/Plymouth-Grades-Final-Excel-2.XLSX') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622a608-4951-4393-841f-792738d6a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5ec85-7d3f-4bc7-9df9-f091465f5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of letter grades to numerical values for analysis\n",
    "grade_mapping = {\n",
    "    'A': 4, 'B': 3, 'C': 2, 'D': 1, 'F': 0, \n",
    "    'NG': 0, 'NP': 0, 'I': 0, 'WF': 0, 'P': 0, 'M': 0\n",
    "}\n",
    "\n",
    "# Define a mapping of letter grades to numerical values for analysis\n",
    "df['Mark_Numerical'] = df['Mark'].map(grade_mapping).fillna(1)  # Default to 1 for unknown marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2906a97-c339-4716-be7f-2a83089ef8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to check for duplicates\n",
    "duplicate_columns = ['Student ID', 'Calendar Month', 'Calendar Year', 'Course ID']\n",
    "\n",
    "# Find duplicate rows based on the specified columns\n",
    "duplicates = df[df.duplicated(subset=duplicate_columns, keep=False)]\n",
    "print(\"Duplicate rows based on specified columns:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d52fd4-60ff-4cdd-8295-91718d34dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows, keeping only the first occurrence\n",
    "df_cleaned = df.drop_duplicates(subset=duplicate_columns, keep='first')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7a503-3fde-4464-aabe-6f7510835d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to add student course attempted and completed\n",
    "def process_student_data_with_totals(df_cleaned, middle_school_grades, high_school_grades):\n",
    "    # Filter data based on grade levels\n",
    "    filtered_df = df_cleaned[df_cleaned['Grade'].isin(middle_school_grades + high_school_grades)]\n",
    "    \n",
    "    # Aggregate to ensure uniqueness of index (Student ID and Name)\n",
    "    aggregated_df = filtered_df.groupby(['Student ID', 'Student Name', 'Course Title']).agg({\n",
    "        'Calendar Month': 'first',\n",
    "        'Calendar Year': 'first',\n",
    "        'Course ID': 'first',\n",
    "        'Grade': 'first',\n",
    "        'Credit Attempted': 'sum',  # Sum the credits\n",
    "        'Credit Completed': 'sum',  # Sum the credits\n",
    "        'School Year': 'first',\n",
    "        'Mark_Numerical': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Create Course Index to pivot by\n",
    "    aggregated_df['Course Index'] = (\n",
    "        aggregated_df.groupby(['Student ID', 'Course Title']).cumcount().astype(str) + '_' + aggregated_df['Course Title']\n",
    "    )\n",
    "    \n",
    "    # Pivot the table so that each course detail becomes its own set of columns\n",
    "    pivoted_data = aggregated_df.pivot(\n",
    "        index=['Student ID', 'Student Name'],\n",
    "        columns='Course Index',\n",
    "        values=[\n",
    "            'Calendar Month', 'Calendar Year', 'Course ID', 'Grade', \n",
    "            'Course Title', 'Credit Attempted', 'Credit Completed', 'School Year', 'Mark_Numerical'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Flatten the multi-level column index\n",
    "    pivoted_data.columns = [f'{col[0]}_{col[1].replace(\" \", \"_\")}' for col in pivoted_data.columns]\n",
    "    \n",
    "    # Reset index to make 'Student ID' and 'Student Name' regular columns\n",
    "    pivoted_data = pivoted_data.reset_index()\n",
    "    \n",
    "    # Identify relevant columns for middle school and high school credit attempted/completed\n",
    "    credit_attempted_columns = [col for col in pivoted_data.columns if 'Credit_Attempted' in col]\n",
    "    credit_completed_columns = [col for col in pivoted_data.columns if 'Credit_Completed' in col]\n",
    "    \n",
    "    # Ensure numeric data\n",
    "    pivoted_data[credit_attempted_columns + credit_completed_columns] = pivoted_data[\n",
    "        credit_attempted_columns + credit_completed_columns\n",
    "    ].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Recalculate totals\n",
    "    pivoted_data['Total_Credit_Attempted'] = pivoted_data[credit_attempted_columns].sum(axis=1, skipna=True)\n",
    "    pivoted_data['Total_Credit_Completed'] = pivoted_data[credit_completed_columns].sum(axis=1, skipna=True)\n",
    "    \n",
    "    # Calculate middle school and high school totals\n",
    "    middle_school_df = df_cleaned[df_cleaned['Grade'].isin(middle_school_grades)]\n",
    "    high_school_df = df_cleaned[df_cleaned['Grade'].isin(high_school_grades)]\n",
    "    \n",
    "    middle_school_credits = middle_school_df.groupby('Student ID')[['Credit Attempted', 'Credit Completed']].sum().rename(\n",
    "        columns={\n",
    "            'Credit Attempted': 'Middle_School_Credit_Attempted',\n",
    "            'Credit Completed': 'Middle_School_Credit_Completed'\n",
    "        }\n",
    "    )\n",
    "    high_school_credits = high_school_df.groupby('Student ID')[['Credit Attempted', 'Credit Completed']].sum().rename(\n",
    "        columns={\n",
    "            'Credit Attempted': 'High_School_Credit_Attempted',\n",
    "            'Credit Completed': 'High_School_Credit_Completed'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Merge back into the pivoted data\n",
    "    pivoted_data = pivoted_data.merge(middle_school_credits, on='Student ID', how='left')\n",
    "    pivoted_data = pivoted_data.merge(high_school_credits, on='Student ID', how='left')\n",
    "    \n",
    "    # Fill NaN values for these columns with 0\n",
    "    pivoted_data.fillna({\n",
    "        'Middle_School_Credit_Attempted': 0,\n",
    "        'Middle_School_Credit_Completed': 0,\n",
    "        'High_School_Credit_Attempted': 0,\n",
    "        'High_School_Credit_Completed': 0\n",
    "    }, inplace=True)\n",
    "    \n",
    "    return pivoted_data\n",
    "\n",
    "# Grade Levels for Middle School and High School\n",
    "middle_school_grades = ['06', '07', '08', '08H']\n",
    "high_school_grades = ['09', '10', '11', '12']\n",
    "\n",
    "# Process the data\n",
    "processed_data = process_student_data_with_totals(df_cleaned, middle_school_grades, high_school_grades)\n",
    "\n",
    "# Add columns to indicate if students met credit requirements\n",
    "processed_data['Middle_School_Completed'] = processed_data['Middle_School_Credit_Completed'] >= 12\n",
    "processed_data['High_School_Completed'] = processed_data['High_School_Credit_Completed'] >= 24\n",
    "\n",
    "# Determine graduation status based only on high school credits\n",
    "processed_data['Graduation_Status'] = processed_data['High_School_Completed'].map({True: 'Graduated', False: 'Not Graduated'})\n",
    "\n",
    "# Display the first few rows with the updated columns\n",
    "processed_data[['Student ID', 'Middle_School_Credit_Attempted', 'Middle_School_Credit_Completed', 'High_School_Credit_Attempted', 'High_School_Credit_Completed', 'Middle_School_Completed', 'High_School_Completed', 'Graduation_Status']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872dbf4-a393-4220-8270-8b75e16ee230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Student ID you're interested in\n",
    "specific_student_id = 306891  # Replace with the actual Student ID you're interested in\n",
    "\n",
    "# Filter the DataFrame to get the row corresponding to the specific Student ID\n",
    "student_row = processed_data[processed_data['Student ID'] == specific_student_id]\n",
    "\n",
    "# Print the Student ID, Credit Attempted, and Credit Completed\n",
    "print(student_row[['Student ID', 'High_School_Credit_Attempted', 'High_School_Credit_Completed']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d79a2-a488-4c9d-ae5b-0fc12181a5d5",
   "metadata": {},
   "source": [
    "## 4. Loading & Exploring Attendance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca820438-06d9-4197-80ed-5522a7c28dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Attendance Excel file\n",
    "df_attendance = pd.read_csv('Plymouth Data/Plymouth-Attendance-Final.CSV') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06baf98-8aec-4177-9549-3f0d3565154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df_attendance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01083631-be2b-4a49-aa51-576351413752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep years that fall within certain range\n",
    "years_to_keep = {str(year) for year in range(2008, 2022)}\n",
    "\n",
    "# Filter rows where 'Year' is in the set of individual years\n",
    "filtered_df_attendance = df_attendance[~df_attendance['School Year'].isin(years_to_keep)]\n",
    "\n",
    "filtered_df_attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1272e95c-def6-481a-9343-60bfc319bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to make one row per student\n",
    "pivoted_df_attendance = filtered_df_attendance.pivot_table(\n",
    "    index=['Student ID', 'Name'],\n",
    "    columns='School Year',\n",
    "    values=['Grade', 'Days Absent', 'Days Membership', 'OrganizationName'],\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Flatten multi-level column names\n",
    "pivoted_df_attendance.columns = ['_'.join(filter(None, col)).strip() for col in pivoted_df_attendance.columns.to_flat_index()]\n",
    "\n",
    "# Rename columns\n",
    "pivoted_df_attendance.rename(columns={'Name': 'Student Name'}, inplace=True)\n",
    "pivoted_df_attendance.head()\n",
    "\n",
    "# Display the result\n",
    "pivoted_df_attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff060bfe-2278-4f53-98be-0b653a733585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinals dictionary for grades, including Kindergarten\n",
    "ordinals = {\n",
    "    0: \"Kindergarten\",\n",
    "    1: \"1st grade\", 2: \"2nd grade\", 3: \"3rd grade\",\n",
    "    4: \"4th grade\", 5: \"5th grade\", 6: \"6th grade\",\n",
    "    7: \"7th grade\", 8: \"8th grade\", 9: \"9th grade\",\n",
    "    10: \"10th grade\", 11: \"11th grade\", 12: \"12th grade\"\n",
    "}\n",
    "\n",
    "# Function to map absences to grade levels based on last available year\n",
    "def map_absences_by_grade(data, absent_columns):\n",
    "    result = []\n",
    "    for index, row in data.iterrows():\n",
    "        # Extract year from column names\n",
    "        year_columns = [(col, int(re.search(r'\\d{4}', col).group())) for col in absent_columns]\n",
    "        \n",
    "        # Identify the last non-NaN year column for this student (senior year)\n",
    "        last_year_col = next((col for col, year in reversed(year_columns) if not pd.isna(row[col])), None)\n",
    "        senior_year = int(re.search(r'\\d{4}', last_year_col).group()) if last_year_col else None\n",
    "        \n",
    "        grade_absences = {ordinals[grade] + ' Absences': 0 for grade in range(0, 13)}  # Include Kindergarten and \"Absences\"\n",
    "        if senior_year:\n",
    "            for col, year in year_columns:\n",
    "                grade_level = 12 - (senior_year - year)  # Map years back to grade levels\n",
    "                if 0 <= grade_level <= 12:\n",
    "                    grade_name = ordinals[grade_level] + ' Absences'  # Add \"Absences\" suffix\n",
    "                    grade_absences[grade_name] = row[col] if not pd.isna(row[col]) else 0\n",
    "\n",
    "        # Include the Student ID in the result\n",
    "        result.append([row['Student ID']] + list(grade_absences.values()))\n",
    "    \n",
    "    # Create a DataFrame from the result and set column names\n",
    "    absences_by_grade_df = pd.DataFrame(result, columns=['Student ID'] + [ordinals[grade] + ' Absences' for grade in range(0, 13)])\n",
    "    return absences_by_grade_df\n",
    "\n",
    "# Extract relevant columns for absences\n",
    "absent_columns = [col for col in pivoted_df_attendance.columns if \"Absent\" in col]\n",
    "\n",
    "# Map the absences to grade levels\n",
    "absences_by_grade_df = map_absences_by_grade(pivoted_df_attendance, absent_columns)\n",
    "\n",
    "# Display the result\n",
    "absences_by_grade_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1771dd0-2fc2-4625-ba5d-8991c120eeef",
   "metadata": {},
   "source": [
    "## 5. Loading & Exploring State Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccae0eb-2b70-4876-85da-36e9388cc95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load State Testing Excel file\n",
    "df_tests = pd.read_excel('Plymouth Data/Plymouth-Tests-Final-Excel.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e696a-20b9-4d59-95a9-82ba493b3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df_tests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ae320-aeac-44ea-9765-0353e49f3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second State Testing Excel file\n",
    "df_tests2 = pd.read_excel('Plymouth Data/Plymouth-Tests-13-16-Excel.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d44677-b291-48d8-a910-22c64e2a209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df_tests2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f84d2c-5a51-46a2-a027-619da92da2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two data frames\n",
    "merged_df = pd.concat([df_tests, df_tests2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be92a6-d1bb-4d1b-b35a-b9a6dec5c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the original data frame to keep \"Student ID\" and \"Scale Score\"\n",
    "pivoted_df_tests = pd.pivot_table(\n",
    "    merged_df,\n",
    "    index=['Student ID'],  # Rows grouped by unique student IDs\n",
    "    columns=['Test Name', 'Part Description'],  # Pivoting by test-related columns\n",
    "    values='Scale Score',  # Keeping only \"Scale Score\" values\n",
    "    aggfunc='first'  # Assuming 'first' to handle duplicates; use 'max' or 'mean' if appropriate\n",
    ")\n",
    "\n",
    "# Flatten multi-level columns into readable column names\n",
    "pivoted_df_tests.columns = ['_'.join(map(str, col)).strip() for col in pivoted_df_tests.columns.to_flat_index()]\n",
    "\n",
    "# Reset index to return a regular DataFrame\n",
    "pivoted_df_tests = pivoted_df_tests.reset_index()\n",
    "\n",
    "# Ensure that all columns except 'Student ID' have 'Score' in their title\n",
    "# Loop through the columns and add 'Score' if it's not already there\n",
    "pivoted_df_tests.columns = [\n",
    "    col if 'Score' in col else f\"{col}_Score\" if col != 'Student ID' else col\n",
    "    for col in pivoted_df_tests.columns\n",
    "]\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df_tests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174b842-88bb-4708-b0d9-bae591a51dd5",
   "metadata": {},
   "source": [
    "## 6. Merge Course History, Attendance, & State Testing Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511a715-22dc-4189-85e9-7e7d48d862cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data sets on 'Student ID'\n",
    "# Start by merging grades and attendance\n",
    "df_final = pd.merge(processed_data, absences_by_grade_df, on='Student ID', how='inner')\n",
    "\n",
    "# Then merge with state_tests\n",
    "final_data = pd.merge(df_final, pivoted_df_tests, on='Student ID', how='inner')\n",
    "\n",
    "# Display the final result\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce420203-18dc-43df-9fac-ebee5838a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate Student IDs\n",
    "duplicate_rows = final_data[final_data.duplicated(subset='Student ID', keep=False)]\n",
    "\n",
    "# Display the duplicate rows\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Duplicate Student IDs found:\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate Student IDs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f544b-104a-4870-b5cf-a82d0cef0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate Student IDs, keeping the first occurrence\n",
    "final_data_cleaned = final_data.drop_duplicates(subset='Student ID', keep='first')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "final_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11fe616-1faf-4eb9-8750-4c89fb458725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of keywords\n",
    "keywords = [\"Student ID\", \"Numeric\", \"Kindergarten\", \"1st grade\", \"2nd grade\", \"3rd grade\", \"4th grade\", \"5th grade\", \"6th grade\", \"7th grade\", \"8th grade\", \"9th grade\", \"10th grade\", \"11th grade\", \"12th grade\" , \"Score\", \"Completed\"]\n",
    "\n",
    "# Filter columns that contain any of the keywords in their name\n",
    "filtered_columns = [col for col in final_data_cleaned.columns if any(keyword in col for keyword in keywords)]\n",
    "\n",
    "# Create a new DataFrame with only the filtered columns\n",
    "final_data_filtered = final_data_cleaned[filtered_columns]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "final_data_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4de43-0662-4b30-9b77-102f297b5ad6",
   "metadata": {},
   "source": [
    "## 7. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df5090-c6f3-4942-a295-142f3af494d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean all string values in the DataFrame\n",
    "final_data_filtered = final_data_filtered.applymap(lambda x: str(x).strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Replace empty strings with NaN to avoid issues\n",
    "final_data_filtered.replace('', float('nan'), inplace=True)\n",
    "\n",
    "# Define the target column (update if 'High_School_Completed' differs)\n",
    "target_column = 'High_School_Completed'\n",
    "\n",
    "# Convert target column to binary if necessary\n",
    "if final_data_filtered[target_column].dtype == 'object':\n",
    "    final_data_filtered[target_column] = final_data_filtered[target_column].map({'True': 1, 'False': 0})\n",
    "\n",
    "# Define feature columns containing relevant keywords\n",
    "keywords = [\"Numeric\", \"Absences\", \"Score\"]\n",
    "features = [\n",
    "    col for col in final_data_filtered.columns\n",
    "    if any(keyword in col for keyword in keywords) and col != target_column\n",
    "]\n",
    "\n",
    "# Extract feature matrix and target\n",
    "X = final_data_filtered[features].apply(pd.to_numeric, errors='coerce')\n",
    "y = final_data_filtered[target_column]\n",
    "\n",
    "# Drop columns with over 90% missing values\n",
    "missing_percentage = X.isnull().mean()\n",
    "X = X.loc[:, missing_percentage <= 0.9]\n",
    "\n",
    "# Handle missing values\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top 20 features\n",
    "top_20_features = feature_importances.head(20)\n",
    "print(\"\\nTop 20 Feature Importances:\")\n",
    "\n",
    "# Shorten feature names by removing everything after a closing parenthesis\n",
    "top_20_features['Feature'] = top_20_features['Feature'].apply(lambda x: x.rpartition(')')[0] if ')' in x else x)\n",
    "\n",
    "# Show the updated top 20 features\n",
    "print(top_20_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7e396-7751-422d-85f9-3cc4b7bbd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all string values in the DataFrame\n",
    "final_data_filtered = final_data_filtered.applymap(lambda x: str(x).strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Replace empty strings with NaN to avoid issues\n",
    "final_data_filtered.replace('', float('nan'), inplace=True)\n",
    "\n",
    "# Define the target column (update if 'High_School_Completed' differs)\n",
    "target_column = 'High_School_Completed'\n",
    "\n",
    "# Convert target column to binary if necessary\n",
    "if final_data_filtered[target_column].dtype == 'object':\n",
    "    final_data_filtered[target_column] = final_data_filtered[target_column].map({'True': 1, 'False': 0})\n",
    "\n",
    "# Define feature columns containing relevant keywords\n",
    "keywords = [\"Numeric\", \"Absences\", \"Score\"]\n",
    "features = [\n",
    "    col for col in final_data_filtered.columns\n",
    "    if any(keyword in col for keyword in keywords) and col != target_column\n",
    "]\n",
    "\n",
    "# Extract feature matrix and target\n",
    "X = final_data_filtered[features].apply(pd.to_numeric, errors='coerce')\n",
    "y = final_data_filtered[target_column]\n",
    "\n",
    "# Drop columns with over 90% missing values\n",
    "missing_percentage = X.isnull().mean()\n",
    "X = X.loc[:, missing_percentage <= 0.9]\n",
    "\n",
    "# Handle missing values\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Shorten feature names for easier visualization\n",
    "def shorten_feature_name(name):\n",
    "    \"\"\"Shorten feature names by truncating after '(' and removing special characters.\"\"\"\n",
    "    name = name.split('(')[0].strip()  # Remove text after the first '('\n",
    "    name = ''.join([c if c.isalnum() or c == '_' else '' for c in name])  # Remove special characters\n",
    "    return name[:20]  # Limit to 20 characters for readability\n",
    "\n",
    "# Generate feature mapping\n",
    "feature_mapping = {col: shorten_feature_name(col) for col in X.columns}\n",
    "shortened_feature_importances = feature_importances.copy()\n",
    "shortened_feature_importances['Feature'] = shortened_feature_importances['Feature'].map(feature_mapping)\n",
    "\n",
    "# Reverse mapping for later use\n",
    "inverse_mapping = {v: k for k, v in feature_mapping.items()}\n",
    "\n",
    "# Display top 20 features with shortened names\n",
    "top_20_features = shortened_feature_importances.head(20)\n",
    "print(\"\\nTop 20 Feature Importances:\")\n",
    "print(top_20_features)\n",
    "\n",
    "# Select data for the top 20 features\n",
    "top_features = X[top_20_features['Feature'].map(inverse_mapping)]\n",
    "correlation_matrix = top_features.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Correlation Heatmap of Top 20 Features')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e5f4c-8dff-49bc-a002-d8a9496043a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define separate feature sets\n",
    "numeric_features = [col for col in features if \"Numeric\" in col]\n",
    "absent_features = [col for col in features if \"Absences\" in col]\n",
    "score_features = [col for col in features if \"Score\" in col]\n",
    "\n",
    "# Dictionary to store top features for each category\n",
    "top_features_by_category = {}\n",
    "\n",
    "# Corrected function with additional NaN handling\n",
    "def analyze_features(feature_subset, category_name):\n",
    "    X_subset = final_data_filtered[feature_subset].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Handle missing values again to ensure no NaNs remain\n",
    "    X_subset = X_subset.fillna(X_subset.mean())  # Fill remaining NaNs with column mean\n",
    "    \n",
    "    # Check for any remaining NaN columns and drop them if necessary\n",
    "    X_subset = X_subset.dropna(axis=1, how='any')  # Drop any columns still containing NaNs\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    print(f\"Accuracy for {category_name}: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': X_subset.columns,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # Display top 10 features\n",
    "    top_10_features = feature_importances.head(10)\n",
    "    print(f\"\\nTop 10 {category_name} Feature Importances:\")\n",
    "    print(top_10_features)\n",
    "    \n",
    "    # Store top 10 features in dictionary\n",
    "    top_features_by_category[category_name] = top_10_features\n",
    "    return top_10_features\n",
    "\n",
    "# Analyze each feature set\n",
    "top_10_numeric = analyze_features(numeric_features, \"Numeric\")\n",
    "top_10_absent = analyze_features(absent_features, \"Absences\")\n",
    "top_10_score = analyze_features(score_features, \"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cfdaa2-e5c7-420a-bf32-1d76d53a9222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the top two features for absences and scores\n",
    "absence_features = top_10_absent['Feature'].iloc[:2]  # Assuming 'Feature' column contains the feature names\n",
    "score_features = top_10_score['Feature'].iloc[:2]     # Assuming 'Feature' column contains the feature names\n",
    "\n",
    "# Match the pattern for OSA Reading K/S, Grade 03 in the feature names\n",
    "osa_pattern = r\"OSA Reading K/S, Grade 03\"  # This pattern can be expanded to handle variations\n",
    "\n",
    "# Match the pattern in the feature names (case-insensitive and allowing partial matches)\n",
    "osa_features = top_10_score['Feature'].str.contains(osa_pattern, case=False, regex=True)\n",
    "\n",
    "# Filter features based on matches\n",
    "matched_osa_features = top_10_score[osa_features]\n",
    "\n",
    "# Update your score_features to include the matched OSA features (flexible matching)\n",
    "score_features = matched_osa_features['Feature'].iloc[:2]  # Adjust to ensure you have the top 2 features including OSA\n",
    "\n",
    "# Filtering relevant data from final_data_filtered using feature names\n",
    "# Remove rows with NaN in any relevant columns for absences\n",
    "absence_data = final_data_filtered[list(absence_features) + ['High_School_Completed']].dropna()\n",
    "X_absences = absence_data[absence_features]\n",
    "y_absences = absence_data['High_School_Completed']\n",
    "\n",
    "# Remove rows with NaN in any relevant columns for scores\n",
    "score_data = final_data_filtered[list(score_features) + ['High_School_Completed']].dropna()\n",
    "X_scores = score_data[score_features]\n",
    "y_scores = score_data['High_School_Completed']\n",
    "\n",
    "# Part 1: Analyzing Absences Thresholds\n",
    "log_reg_absences = LogisticRegression()\n",
    "log_reg_absences.fit(X_absences, y_absences)\n",
    "\n",
    "# Define thresholds for absences (students who exceed these values are more likely to not graduate)\n",
    "max_grade_12_absences = 15\n",
    "max_grade_11_absences = 15\n",
    "\n",
    "# Determine probabilities across a range of absences for Grade 12 and Grade 11\n",
    "absences_range = np.linspace(0, 15, 100)  # Range of absence values\n",
    "absences_probabilities = {\n",
    "    'Grade 12 Absences': [],\n",
    "    'Grade 11 Absences': []\n",
    "}\n",
    "\n",
    "for grade_12_abs in absences_range:\n",
    "    prob_12 = log_reg_absences.predict_proba(\n",
    "        pd.DataFrame([[grade_12_abs, 0]], columns=absence_features)  # Grade 11 absence is 0 for now\n",
    "    )[0][1]\n",
    "    absences_probabilities['Grade 12 Absences'].append((grade_12_abs, prob_12))\n",
    "\n",
    "for grade_11_abs in absences_range:\n",
    "    prob_11 = log_reg_absences.predict_proba(\n",
    "        pd.DataFrame([[0, grade_11_abs]], columns=absence_features)  # Grade 12 absence is 0 for now\n",
    "    )[0][1]\n",
    "    absences_probabilities['Grade 11 Absences'].append((grade_11_abs, prob_11))\n",
    "\n",
    "# Find thresholds where probability of graduation drops below 50% for both features\n",
    "def find_threshold(probabilities, threshold=0.5):\n",
    "    thresholds = [(value, prob) for value, prob in probabilities if prob < threshold]\n",
    "    return min(thresholds, key=lambda x: x[1]) if thresholds else None\n",
    "\n",
    "grade_12_absence_threshold = find_threshold(absences_probabilities['Grade 12 Absences'])\n",
    "grade_11_absence_threshold = find_threshold(absences_probabilities['Grade 11 Absences'])\n",
    "\n",
    "# Display the result for absences\n",
    "print(f\"Grade 12 Absences Threshold (Absence, Probability): {grade_12_absence_threshold}\")\n",
    "print(f\"Grade 11 Absences Threshold (Absence, Probability): {grade_11_absence_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db8b8f-99b2-4819-be3e-e1894a319242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns based on the specific test titles\n",
    "specific_test_columns = final_data_filtered.columns[final_data_filtered.columns.str.contains('OSA Reading K/S, Grade 03 \\(1B\\), 2005_Demonstrate General Understanding_Score|SBA MA HS_Communicating Reasoning_Score', case=False)]\n",
    "\n",
    "# Add the target variable 'High_School_Completed' to the list of selected columns\n",
    "test_columns = list(specific_test_columns) + ['High_School_Completed']\n",
    "\n",
    "# Filter the DataFrame to include only the relevant columns\n",
    "filtered_data = final_data_filtered[test_columns]\n",
    "\n",
    "# Check for missing values in the filtered data\n",
    "print(filtered_data.isnull().sum())\n",
    "\n",
    "# Handle missing data (e.g., fill with mean or drop rows)\n",
    "filtered_data_filled = filtered_data.fillna(filtered_data.mean())  # Or drop rows with dropna() if preferred\n",
    "\n",
    "# Verify if there are any missing values left\n",
    "print(filtered_data_filled.isnull().sum())\n",
    "\n",
    "# Define your features (X) and target variable (y)\n",
    "X_testing = filtered_data_filled[specific_test_columns]\n",
    "y_testing = filtered_data_filled['High_School_Completed']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_testing, X_test_testing, y_train_testing, y_test_testing = train_test_split(X_testing, y_testing, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the logistic regression model\n",
    "log_reg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "log_reg_model.fit(X_train_testing, y_train_testing)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_testing = log_reg_model.predict(X_test_testing)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_testing, y_pred_testing))\n",
    "\n",
    "# Obtain the predicted probabilities for the logistic regression model\n",
    "probabilities = log_reg_model.predict_proba(X_test_testing)[:, 1]  # Get the probabilities for the positive class (graduation)\n",
    "\n",
    "# Calculate the absolute difference between predicted probabilities and 50%\n",
    "probability_diff = abs(probabilities - 0.5)\n",
    "\n",
    "# Find the indices of the closest probabilities to 50%\n",
    "closest_indices = probability_diff.argsort()[:10]  # Get the top 10 closest\n",
    "\n",
    "# Get the corresponding test scores and probabilities\n",
    "closest_scores = X_test_testing.iloc[closest_indices]\n",
    "closest_probs = probabilities[closest_indices]\n",
    "\n",
    "# Combine the test scores and probabilities into a DataFrame for easy viewing\n",
    "results = pd.DataFrame(closest_scores)\n",
    "results['Predicted Probability'] = closest_probs\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nScores closest to a 50% probability of graduating:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065594a2-76df-4e09-ad0d-7a6bf558f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns based on the specific test titles\n",
    "specific_test_columns = final_data_filtered.columns[final_data_filtered.columns.str.contains('OSA Reading K/S, Grade 03 \\(1B\\), 2005_Demonstrate General Understanding_Score|SBA MA HS_Communicating Reasoning_Score', case=False)]\n",
    "\n",
    "# Add the target variable 'High_School_Completed' to the list of selected columns\n",
    "test_columns = list(specific_test_columns) + ['High_School_Completed']\n",
    "\n",
    "# Filter the DataFrame to include only the relevant columns\n",
    "filtered_data = final_data_filtered[test_columns]\n",
    "\n",
    "# Check for missing values in the filtered data\n",
    "print(filtered_data.isnull().sum())\n",
    "\n",
    "# Handle missing data (e.g., fill with mean or drop rows)\n",
    "filtered_data_filled = filtered_data.fillna(filtered_data.mean())  # Or drop rows with dropna() if preferred\n",
    "\n",
    "# Verify if there are any missing values left\n",
    "print(filtered_data_filled.isnull().sum())\n",
    "\n",
    "# Define your features (X_scoring) and target variable (y_scoring)\n",
    "X_scoring = filtered_data_filled[specific_test_columns]\n",
    "y_scoring = filtered_data_filled['High_School_Completed']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_scoring, X_test_scoring, y_train_scoring, y_test_scoring = train_test_split(X_scoring, y_scoring, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the logistic regression model with class weights\n",
    "log_reg_model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Fit the model\n",
    "log_reg_model.fit(X_train_scoring, y_train_scoring)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_scoring = log_reg_model.predict(X_test_scoring)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_scoring, y_pred_scoring))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_scoring, y_pred_scoring)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Obtain the predicted probabilities for the logistic regression model\n",
    "probabilities_scoring = log_reg_model.predict_proba(X_test_scoring)[:, 1]  # Get the probabilities for the positive class (graduation)\n",
    "\n",
    "# Calculate the absolute difference between predicted probabilities and 50%\n",
    "probability_diff_scoring = abs(probabilities_scoring - 0.5)\n",
    "\n",
    "# Find the indices of the closest probabilities to 50%\n",
    "closest_indices_scoring = probability_diff_scoring.argsort()[:10]  # Get the top 10 closest\n",
    "\n",
    "# Get the corresponding test scores and probabilities\n",
    "closest_scores_scoring = X_test_scoring.iloc[closest_indices_scoring]\n",
    "closest_probs_scoring = probabilities_scoring[closest_indices_scoring]\n",
    "\n",
    "# Combine the test scores and probabilities into a DataFrame for easy viewing\n",
    "results_scoring = pd.DataFrame(closest_scores_scoring)\n",
    "results_scoring['Predicted Probability'] = closest_probs_scoring\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nScores closest to a 50% probability of graduating:\")\n",
    "print(results_scoring)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f16bb8-5ffa-470f-af58-4ca92f7586e8",
   "metadata": {},
   "source": [
    "## 8. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d033322-bf14-4fce-a03c-ed1c9f5e8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the three categories\n",
    "numeric_features = [col for col in X.columns if \"Numeric\" in col]\n",
    "absent_features = [col for col in X.columns if \"Absences\" in col]\n",
    "score_features = [col for col in X.columns if \"Score\" in col]\n",
    "\n",
    "# Calculate total importance for each category\n",
    "total_importance_numeric = feature_importances.loc[feature_importances['Feature'].isin(numeric_features), 'Importance'].sum()\n",
    "total_importance_absent = feature_importances.loc[feature_importances['Feature'].isin(absent_features), 'Importance'].sum()\n",
    "total_importance_score = feature_importances.loc[feature_importances['Feature'].isin(score_features), 'Importance'].sum()\n",
    "\n",
    "# Combine into a dictionary for easier visualization\n",
    "category_importances = {\n",
    "    'Numeric': total_importance_numeric,\n",
    "    'Absences': total_importance_absent,\n",
    "    'Score': total_importance_score\n",
    "}\n",
    "\n",
    "# Display category importance breakdown\n",
    "print(\"\\nTotal Importance by Category:\")\n",
    "for category, importance in category_importances.items():\n",
    "    print(f\"{category}: {importance:.4f}\")\n",
    "\n",
    "# Plot the importance breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(category_importances.keys(), category_importances.values(), color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "plt.title('Feature Importance Breakdown by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Total Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9941e1-f3de-41c1-8991-b7f146736468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Graduated', 'Graduated'], yticklabels=['Not Graduated', 'Graduated'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a288bad-dd8a-4f65-89be-84566430a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 20 feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_20_features, palette='viridis')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ec6f7-33fe-4e79-8438-22a1786373b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative importance\n",
    "top_20_features['Cumulative Importance'] = top_20_features['Importance'].cumsum()\n",
    "\n",
    "# Plot cumulative importance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 21), top_20_features['Cumulative Importance'], marker='o', linestyle='--', color='b')\n",
    "plt.xticks(range(1, 21), top_20_features['Feature'], rotation=90)\n",
    "plt.title('Cumulative Feature Importance')\n",
    "plt.xlabel('Top Features')\n",
    "plt.ylabel('Cumulative Importance')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bb54d-1c34-433d-b53a-ebabf0e5f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing distribution of top 20 features\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(top_20_features['Importance'], bins=10, kde=True, color='teal')\n",
    "plt.title('Distribution of Top 20 Feature Importances')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf51bca-3e1d-4fdf-b6ca-2cde1bd2ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing top features for a given category and saving the chart\n",
    "def plot_top_features(category, save_path=None):\n",
    "    top_features = top_features_by_category[category]\n",
    "    \n",
    "    # Normalize feature importances for color mapping\n",
    "    importance_values = top_features['Importance'].values\n",
    "    norm = plt.Normalize(min(importance_values), max(importance_values))\n",
    "    colors = cm.viridis(norm(importance_values))  # Use viridis colormap\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(top_features['Feature'], top_features['Importance'], color=colors)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 10 Features for {category}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize top Numeric features and save chart\n",
    "plot_top_features('Numeric', save_path='top_features_numeric.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab691aee-009b-4b5b-83e8-a69c92dc91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top Absent features\n",
    "plot_top_features('Absences', save_path='top_features_absences.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b683933-ed1e-47b3-8e15-13ddd31baa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top Score features\n",
    "plot_top_features('Score', save_path='top_features_absences.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587c61a-96a3-459b-a80e-891ff59cace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test_scoring, y_pred_scoring)\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Graduated', 'Graduated'], yticklabels=['Not Graduated', 'Graduated'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892d279-0071-40bc-8a0a-1d44e5ee43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the top two features for absences and scores\n",
    "absence_features = top_10_absent['Feature'].iloc[:2]\n",
    "score_features = top_10_score['Feature'].iloc[:2] \n",
    "\n",
    "# Match the pattern for OSA Reading K/S, Grade 03 in the feature names\n",
    "osa_pattern = r\"OSA Reading K/S, Grade 03\"  # This pattern can be expanded to handle variations\n",
    "\n",
    "# Match the pattern in the feature names (case-insensitive and allowing partial matches)\n",
    "osa_features = top_10_score['Feature'].str.contains(osa_pattern, case=False, regex=True)\n",
    "\n",
    "# Filter features based on matches\n",
    "matched_osa_features = top_10_score[osa_features]\n",
    "\n",
    "# If there are multiple matches, you can inspect or select the first one\n",
    "#print(\"Matched OSA Features:\")\n",
    "#print(matched_osa_features)\n",
    "\n",
    "# Update your score_features to include the matched OSA features (flexible matching)\n",
    "score_features = matched_osa_features['Feature'].iloc[:2]\n",
    "\n",
    "# Filtering relevant data from final_data_filtered using feature names\n",
    "grade_absence_columns = ['8th grade Absences', '9th grade Absences', '10th grade Absences', '11th grade Absences', '12th grade Absences']\n",
    "\n",
    "# Ensure relevant columns and target are present\n",
    "columns_to_use = grade_absence_columns + ['High_School_Completed']\n",
    "attendance_data = final_data_filtered[columns_to_use].dropna()\n",
    "\n",
    "# Splitting data by grade and modeling each one\n",
    "logistic_regressions = {}\n",
    "probabilities_by_grade = {}\n",
    "absences_range = np.linspace(0, attendance_data[grade_absence_columns].max().max(), 100)\n",
    "\n",
    "for grade in grade_absence_columns:\n",
    "    X = attendance_data[[grade]]  # Use attendance column for the specific grade\n",
    "    y = attendance_data['High_School_Completed']\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y)\n",
    "    logistic_regressions[grade] = log_reg\n",
    "    probabilities_by_grade[grade] = log_reg.predict_proba(absences_range.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "for grade, color in zip(grade_absence_columns, colors):\n",
    "    plt.plot(absences_range, probabilities_by_grade[grade], label=f\"{grade.replace('_', ' ')}\", color=color, linewidth=2)\n",
    "\n",
    "plt.axhline(y=0.5, color='black', linestyle='--', label='50% Probability Threshold')\n",
    "plt.title(\"Days Attended vs Probability of Graduation (Grades 8-12)\")\n",
    "plt.xlabel(\"Number of Days Attended\")\n",
    "#plt.xlim(0, 90)\n",
    "plt.ylabel(\"Probability of Graduation\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35805cea-3ee7-49a3-a02e-119c81fc427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of rows and columns for the grid\n",
    "n_rows = 2\n",
    "n_cols = 3\n",
    "\n",
    "# Create a figure with a grid of subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each grade and plot on the corresponding subplot\n",
    "for idx, grade in enumerate(grade_absence_columns):\n",
    "    # Scatter plot\n",
    "    sns.scatterplot(data=attendance_data, x=grade, y='High_School_Completed', alpha=0.6, ax=axes[idx])\n",
    "\n",
    "    # Prepare data for logistic regression\n",
    "    X = attendance_data[[grade]]  # Attendance data\n",
    "    y = attendance_data['High_School_Completed']  # Graduation outcome\n",
    "    \n",
    "    # Fit logistic regression\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Create a range of values for attendance to plot the logistic curve\n",
    "    x_range = np.linspace(X[grade].min(), X[grade].max(), 300).reshape(-1, 1)\n",
    "    \n",
    "    # Predict probabilities for the logistic curve\n",
    "    y_prob = model.predict_proba(x_range)[:, 1]\n",
    "    \n",
    "    # Plot the logistic regression curve\n",
    "    axes[idx].plot(x_range, y_prob, color='red', label='Logistic Curve')\n",
    "    \n",
    "    # Customize plot\n",
    "    axes[idx].set_title(f\"{grade.replace('_', ' ')} vs Graduation Outcome\")\n",
    "    axes[idx].set_xlabel(\"Days Attended\")\n",
    "    axes[idx].set_ylabel(\"Graduation (0 = No, 1 = Yes)\")\n",
    "    axes[idx].grid(True)\n",
    "    axes[idx].legend()\n",
    "\n",
    "# Hide the last subplot if there's an extra one\n",
    "axes[-1].axis('off')\n",
    "\n",
    "# Adjust layout to make it look nice\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae0e78-bc54-42ae-99fa-2cf43e93fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for pairwise plot relationships\n",
    "def plot_pairwise_relationships(top_features, category_name, target_column):\n",
    "    selected_features = top_features['Feature'].tolist()\n",
    "    # Add the correct target column to the subset\n",
    "    subset_data = final_data_filtered[selected_features].copy()\n",
    "    subset_data[target_column] = y  # Add target variable\n",
    "    \n",
    "    sns.pairplot(subset_data, hue=target_column, palette='Set2', diag_kind='kde')\n",
    "    plt.suptitle(f\"Pairwise Relationships in Top {category_name} Features\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Pass the correct target column name\n",
    "plot_pairwise_relationships(top_10_numeric, \"Numeric\", target_column=\"High_School_Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
